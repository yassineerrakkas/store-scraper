{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet de Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERRAKKAS Yassine , INE 1 Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### l'idée du projet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet est la première partie d'un grand projet, ce grand projet concerne un robot de recommandation, il vous suffit de lui donner un article que vous voulez acheter en ligne, et il vous donnera le lien du meilleur article.\n",
    "Pour cette première partie, nous nous concentrons sur le scraping de données, nous commencerons par ebay, aliexpress et amazon pour ce prototype. par la suite, nous ajouterons d'autres sites web."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'implémentation avec python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les bibliothèques que nous utilisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appeler le navigateur pour obtenir les sites web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction prend en paramètre un Xpath d'éléments et retourne le texte dans ces éléments si on donne 0 dans le deuxieme paramètre et les liens si on donne 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_xpath_to_text(xpath, option):\n",
    "    element_list = driver.find_elements(\n",
    "        By.XPATH, xpath)\n",
    "    elements = []\n",
    "    if option == 0:\n",
    "        for element in element_list:\n",
    "            elements.append(element.text)\n",
    "    elif option == 1:\n",
    "        for element in element_list:\n",
    "            elements.append(element.get_attribute('href'))\n",
    "    return elements\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur ebay, on trouve parfois dans un élément la phrase \"Top rated seller\" et le nom du vendeur. C'est pourquoi nous avons écrit cette fonction pour supprimer cette phrase et ne garder que le nom du vendeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saller_names_filter(nonFiltredNames):\n",
    "    filtrednames = []\n",
    "    for i in nonFiltredNames:\n",
    "        if i == 'Top Rated Seller':\n",
    "            continue\n",
    "        else :\n",
    "            filtrednames.append(i.split()[0])\n",
    "    return filtrednames\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces trois fonctions renvoient un dictionnaire qui contient les titres, les prix, les vendeurs et les liens de tous les articles de la page. la première est pour ebay, la deuxième pour aliexpress et la troisième pour amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebayScraper(input):\n",
    "    \n",
    "    ebay_title_xpath = '//*[@id=\"srp-river-results\"]/ul/li/div/div[2]/a/div/span'\n",
    "    ebay_itemLink_xpath = '//*[@id=\"srp-river-results\"]/ul/li/div/div[2]/a'\n",
    "    ebay_price_xpath = '//*[@id=\"srp-river-results\"]/ul/li/div/div[2]/div/div[1]/span'\n",
    "    ebay_seller_xpath = '//*[@id = \"srp-river-results\"]/ul/li/div/div[2]/div/span/span/span'\n",
    "\n",
    "    driver.get('https://www.ebay.com/')\n",
    "    # search bar\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"gh-ac\"]').send_keys(input)\n",
    "    # search button\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"gh-btn\"]').click()\n",
    "    \n",
    "    titles = element_xpath_to_text(ebay_title_xpath, 0)\n",
    "    links = element_xpath_to_text(ebay_itemLink_xpath, 1)\n",
    "    prices = element_xpath_to_text(ebay_price_xpath, 0)\n",
    "    sellers = saller_names_filter(element_xpath_to_text(ebay_seller_xpath, 0))\n",
    "    return {'titles': titles, 'prices': prices, 'sellers': sellers, 'links': links}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aliexpressScraper(input):\n",
    "    \n",
    "    ali_title_xpath = '// *[@id=\"root\"]/div/div/div[2]/div/div[2]/div[3]/a/div[2]/div[4]/h1'\n",
    "    ali_itemLink_xpath = '//*[@id=\"root\"]/div/div/div[2]/div/div[2]/div[3]/a'\n",
    "    ali_price_xpath = '//*[@id=\"root\"]/div/div/div[2]/div/div[2]/div[3]/a/div[2]/div[1]/div[1]'\n",
    "    ali_seller_xpath = '//*[@id=\"root\"]/div/div/div[2]/div/div[2]/div[3]/a/div[2]/span/a'\n",
    "\n",
    "    driver.get('https://www.aliexpress.com/')\n",
    "    # search bar\n",
    "    driver.find_element(By.XPATH, '// *[@id=\"search-key\"]').send_keys(input)\n",
    "    # search button \n",
    "    driver.find_element(By.XPATH, '//*[@id = \"form-searchbar\"]/div[1]/input').click()\n",
    "    # for more content\n",
    "    driver.execute_script('window.scrollTo(e, document.body.scrollHeight);')\n",
    "\n",
    "    titles = element_xpath_to_text(ali_title_xpath, 0)\n",
    "    prices = element_xpath_to_text(ali_price_xpath, 0)\n",
    "    sellers = element_xpath_to_text(ali_seller_xpath, 0)\n",
    "    links = element_xpath_to_text(ali_itemLink_xpath, 1)\n",
    "    return {'titles': titles, 'prices': prices, 'sellers': sellers, 'links': links}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AmazonScaper(input):\n",
    "    driver.get('https://www.amazon.com/')\n",
    "    driver.find_element(\n",
    "        By.XPATH, '//*[@id=\"twotabsearchtextbox\"]').send_keys(input)\n",
    "    driver.find_element(\n",
    "        By.XPATH, '//*[@id=\"nav-search-submit-button\"]').click()\n",
    "    html = driver.page_source\n",
    "    source = BeautifulSoup(html, \"lxml\")\n",
    "    itemsdiv = source.find_all(\n",
    "        'div', {'data-asin': True, 'data-component-type': 's-search-result'})\n",
    "    titles = []\n",
    "    links = []\n",
    "    prices = []\n",
    "    sellers = []\n",
    "    for itemdiv in itemsdiv:\n",
    "        try:\n",
    "            h2 = itemdiv.h2\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            titles.append(h2.text)\n",
    "            links.append('https://www.amazon.com'+h2.a.get('href'))\n",
    "            prices.append(itemdiv.find('span', class_='a-price-symbol').text+itemdiv.find('span', class_='a-price-whole').text +\n",
    "                                itemdiv.find('span', class_='a-price-fraction').text)\n",
    "            sellers.append('Null')\n",
    "    return {'titles' : titles,'prices':prices,'sellers':sellers,'links':links}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cette fonction permet d'écrire un fichier csv qui contient toutes les données que nous récupérons, elle prend un dictionnaire de données et le nom du fichier csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_csv_file(data,filename):\n",
    "    with open(filename+'.csv','a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data.keys())\n",
    "        for i in range(len(list(data.values())[0])):\n",
    "            writer.writerow(val[i] for val in list(data.values()))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "un exemple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ebayScraper('galaxy s10 case')\n",
    "Write_csv_file(data,'ebay_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
